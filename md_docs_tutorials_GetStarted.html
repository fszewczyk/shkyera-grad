<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Shkyera Grad: Get Started</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Shkyera Grad
   &#160;<span id="projectnumber">0.0.1</span>
   </div>
   <div id="projectbrief">micrograd, but in C++ and better</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_docs_tutorials_GetStarted.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Get Started </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Hello! Let's get right into it. By the end of this guide, you will have created and trained your first neural in <em>Shkyera Grad</em>!</p>
<h1><a class="anchor" id="autotoc_md10"></a>
Setup</h1>
<p>This is easy, <em>Shkyera Grad</em> is a header-only library, so simply clone the repositoryu into your project:</p>
<div class="fragment"><div class="line">git clone https://github.com/fszewczyk/shkyera-grad.git</div>
</div><!-- fragment --><p>and import the main file of the library inside your own project.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;shkyera-grad/include/ShkyeraGrad.hpp&quot;</span></div>
</div><!-- fragment --><p>Now, you can use all the features of this small engine.</p>
<dl class="section note"><dt>Note</dt><dd><em>Shkyera Grad</em> is tested in C++17. Make sure your compiler supports this version.</dd></dl>
<h1><a class="anchor" id="autotoc_md11"></a>
Scalars</h1>
<p>Internally, <em>Shkyera Grad</em> <b>always</b> operates on individual scalars. For most purposes, you do not need to deal with them directly, but it's nice to understand how they work. Each scalar is wrapped inside a <code>Value</code> class. However, you should never instantiate objects of this type yourself. Instead, you should use the provided interface in the following way.</p>
<div class="fragment"><div class="line"><span class="comment">// Creates a floating-point scalar</span></div>
<div class="line">ValuePtr&lt;float&gt; a = Value&lt;float&gt;::create(5.2);</div>
<div class="line">ValuePtr&lt;Type::f32&gt; a = Value&lt;Type::f32&gt;::create(5.2);</div>
<div class="line">ValuePtr&lt;Type::float32&gt; a = Value&lt;Type::float32&gt;::create(5.2);</div>
<div class="line"><span class="keyword">auto</span> a = Value&lt;float&gt;::create(5.2);</div>
<div class="line"><span class="keyword">auto</span> a = Value&lt;Type::float32&gt;::create(5.2);</div>
<div class="line"><span class="keyword">auto</span> a = Value&lt;Type::float64&gt;::create(5.2);</div>
<div class="line"><span class="keyword">auto</span> a = Val32::create(5.2);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Now with higher precision!</span></div>
<div class="line">ValuePtr&lt;Type::float64&gt; b = Value&lt;double&gt;::create(6.9);</div>
<div class="line"><span class="keyword">auto</span> b = Value&lt;Type::f64&gt;::create(6.9);</div>
<div class="line"><span class="keyword">auto</span> b = Val64::create(6.9);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// You can also use integers, no clue why, but go for it!</span></div>
<div class="line"><span class="keyword">auto</span> c = Value&lt;int&gt;::create(7);</div>
</div><!-- fragment --><p>You can also perform various operations directly on scalars!</p>
<div class="fragment"><div class="line"><span class="keyword">using</span> T = Type::float32;</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> a = Value&lt;T&gt;::create(2.1);</div>
<div class="line"><span class="keyword">auto</span> b = Value&lt;T&gt;::create(3.7);</div>
<div class="line"><span class="keyword">auto</span> c = a - b;</div>
<div class="line"><span class="keyword">auto</span> d = a * b / c;</div>
<div class="line">c = d-&gt;log();</div>
<div class="line"><span class="keyword">auto</span> e = (a + b - c)-&gt;pow(d);</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Check out the cheatsheet for the list of all operations.</dd></dl>
<p>The magic behind the <em>Shkyera Grad</em> is that it keeps track of all the operations, so that you can later calculate the derivatives of your expression.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> a = Value&lt;T&gt;::create(2.0);</div>
<div class="line"><span class="keyword">auto</span> b = Value&lt;T&gt;::create(3.0);</div>
<div class="line"><span class="keyword">auto</span> c = a * b;</div>
<div class="line"> </div>
<div class="line">c-&gt;getValue();                  <span class="comment">// c = 6.0</span></div>
<div class="line">c-&gt;backward();                  <span class="comment">// Calculate the gradients of the expression</span></div>
<div class="line"> </div>
<div class="line">a-&gt;getGradient();               <span class="comment">// dc/da = 3.0</span></div>
<div class="line">b-&gt;getGradient();               <span class="comment">// dc/db = 2.0</span></div>
</div><!-- fragment --><p>If you want some refreshment on derivatives, check out <a href="https://www.youtube.com/watch?v=9vKqVkMQHKk">this wonderful video</a>.</p>
<h1><a class="anchor" id="autotoc_md12"></a>
Vector</h1>
<p>Multiple scalars can be grouped together in a <code>Vector</code> to simplify operating on them. Input to any <code>Module</code> (more on them later) is a <code>Vector</code>. This abstraction provides some functionality that allows you to compute, for example a dot product.</p>
<div class="fragment"><div class="line"><span class="comment">// The easiest way to create e Vector</span></div>
<div class="line"><span class="keyword">auto</span> a = Vector&lt;T&gt;::of(1, 2, 3);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// A bit more annoying way to create a Vector</span></div>
<div class="line"><span class="keyword">auto</span> b = Vector&lt;T&gt;::of({1, 2, 3});</div>
<div class="line"> </div>
<div class="line"><span class="comment">// The hard way to create a Vector</span></div>
<div class="line"><span class="keyword">auto</span> c = Vector&lt;T&gt;(Value&lt;T&gt;::create(2), Value&lt;T&gt;::create(3), Value&lt;T&gt;::create(4));</div>
<div class="line"> </div>
<div class="line"><span class="comment">// You can access elements in a vector</span></div>
<div class="line"><span class="keyword">auto</span> d = Vector&lt;T&gt;::of({a[0]*b[0], a[1]*b[1], a[2]*b[2]});</div>
<div class="line"> </div>
<div class="line"><span class="comment">// And even iterate over it</span></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keyword">auto</span> &amp;entry : d)</div>
<div class="line">    std::cout &lt;&lt; entry &lt;&lt; std::endl; <span class="comment">// prints: 2 6 12</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> e = b.dot(c)       <span class="comment">// c = 1 * 2 + 2 * 3 + 3 * 4 = 20</span></div>
<div class="line">e-&gt;backward();          <span class="comment">// You can compute of this result since it&#39;s a scalar!</span></div>
</div><!-- fragment --><p><code>Vectors</code> are very useful since this is the way both the input and output data is represented. Each sample consits of an input <code>Vector</code> and a target output <code>Vector</code>.</p>
<h1><a class="anchor" id="autotoc_md13"></a>
Sequential</h1>
<p>Nice! You got the basics! Let's build a network. The best way to create a model is through the use of the <code>Sequential</code> interface. Each function that transforms an input <code>Vector</code> into some output <code>Vector</code> is implemented as a <code>Module</code>. This includes neural layers as well as activation functions. Hey, even <code>Sequential</code> is a <code>Module</code>. This allows for creating complex strctures while using a common, simple interface.</p>
<p>You can create your first neural network using <code>SequentialBuilder</code> in the following way.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> network = SequentialBuilder&lt;T&gt;::begin()</div>
<div class="line">               .add(Linear&lt;T&gt;::create(2, 15))       <span class="comment">// Adds a layer with 2 inputs and 15 outputs</span></div>
<div class="line">               .add(ReLU&lt;T&gt;::create())              <span class="comment">// Adds a ReLU activation function</span></div>
<div class="line">               .add(Linear32::create(15, 10))       <span class="comment">// You can use {Layer}32 or {Layer}64 macros</span></div>
<div class="line">               .add(Sigmoid32::create())            <span class="comment">// More fancy activation :0</span></div>
<div class="line">               .add(Dropout32::create(10, 2, 0.5))  <span class="comment">// We use the dropout rate of 0.5</span></div>
<div class="line">               .build();                            <span class="comment">// Don&#39;t forget to actually build your network</span></div>
</div><!-- fragment --><dl class="section warning"><dt>Warning</dt><dd>Remember that subsequent layers have to have matching input and output sizes.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>For the full list of available layers and activation functions, check out the Cheat Sheet.</dd></dl>
<h1><a class="anchor" id="autotoc_md14"></a>
Training</h1>
<p>To train our network, we need to define an <code>Optimizer</code> that will optimizer the parameters as well as the <code>Loss</code> function that we will minimize. <em>Shkyera Grad</em> comes with a set of well-known optimizers and loss functions. Again, check out the Cheat Sheet for a complete list.</p>
<div class="fragment"><div class="line"><span class="comment">// Simple stochastic gradient descent optimizer with 0.01 learning rate</span></div>
<div class="line"><span class="keyword">auto</span> optimizer = Optimizer&lt;T&gt;(network-&gt;parameters(), 0.01);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Stochastic gradient descent, but with momentum of 0.99!</span></div>
<div class="line"><span class="comment">// If you provide no parameter for momentum, it defaults to 0.9</span></div>
<div class="line"><span class="keyword">auto</span> betterOptimizer = SGD32(network-&gt;parameters(), 0.01, 0.99);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Recommended optimizer: Adam as described in the original paper</span></div>
<div class="line"><span class="comment">// Again, 0.01 is the learning rate.</span></div>
<div class="line"><span class="keyword">auto</span> awesomeOptimizer = Adam32(network-&gt;parameters(), 0.01);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// By default, it comes with the recommended parameters,</span></div>
<div class="line"><span class="comment">// but they can be changed if you feel like it in the following way:</span></div>
<div class="line"><span class="keyword">auto</span> awesomeCustomOptimizer = Adam32(network-&gt;parameters(), 0.01, beta1, beta2, epsilon);</div>
</div><!-- fragment --><p>Here's a list of some available <code>Loss</code> functions:</p>
<div class="fragment"><div class="line">Loss::MAE&lt;T&gt;            <span class="comment">// Mean Absolute Error</span></div>
<div class="line">Loss::MSE&lt;T&gt;            <span class="comment">// Mean Squared Error</span></div>
<div class="line">Loss::CrossEntropy&lt;T&gt;   <span class="comment">// Cross Entropy Loss - good for classification</span></div>
</div><!-- fragment --><p>They are implemented as lambda functions, not as objects, so they do not need to be instantiated.</p>
<h1><a class="anchor" id="autotoc_md15"></a>
Learning XOR</h1>
<p>XOR (Exclusive OR) is a simple Boolean function that maps two values two one:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">X1   </th><th class="markdownTableHeadNone">X2   </th><th class="markdownTableHeadNone">Result    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">0    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">1    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">0   </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md16"></a>
Let's define our dataset.</h2>
<p>Here, we basically pase the table above into <code>Vector</code>s.</p>
<div class="fragment"><div class="line">std::vector&lt;Vec32&gt; xs;</div>
<div class="line">std::vector&lt;Vec32&gt; ys;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// ---------- INPUT ----------- | -------- OUTPUT --------- //</span></div>
<div class="line">xs.push_back(Vec32::of(0, 0)); ys.push_back(Vec32::of(0));</div>
<div class="line">xs.push_back(Vec32::of(1, 0)); ys.push_back(Vec32::of(1));</div>
<div class="line">xs.push_back(Vec32::of(0, 1)); ys.push_back(Vec32::of(1));</div>
<div class="line">xs.push_back(Vec32::of(1, 1)); ys.push_back(Vec32::of(0));</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md17"></a>
Neural Network</h2>
<p>We define a simple neural network to predict this function. Our network has a total of three layers. It is a bit of an overkill for this task, but we will use it for learning purposes.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> network = SequentialBuilder&lt;Type::float32&gt;::begin()</div>
<div class="line">                .add(Linear32::create(2, 15))</div>
<div class="line">                .add(ReLU32::create())</div>
<div class="line">                .add(Linear32::create(15, 5))</div>
<div class="line">                .add(ReLU32::create())</div>
<div class="line">                .add(Linear32::create(5, 1))</div>
<div class="line">                .add(Sigmoid32::create())</div>
<div class="line">                .build();</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md18"></a>
Training Loop</h2>
<p>Now, we just need to specify the optimizer and the loss function we want to use:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> optimizer = Adam32(network-&gt;parameters(), 0.05);</div>
<div class="line"><span class="keyword">auto</span> lossFunction = Loss::MSE&lt;T&gt;;</div>
</div><!-- fragment --><p>We train our model for 100 epochs. After each epoch, we pring the average loss.</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> epoch = 0; epoch &lt; 100; epoch++) {              <span class="comment">// We train for 100 epochs</span></div>
<div class="line">    <span class="keyword">auto</span> epochLoss = Val32::create(0);</div>
<div class="line"> </div>
<div class="line">    optimizer.reset();                                      <span class="comment">// Reset the gradients</span></div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> sample = 0; sample &lt; xs.size(); ++sample) { <span class="comment">// We go through each sample</span></div>
<div class="line">        Vec32 pred = network-&gt;forward(xs[sample]);          <span class="comment">// We get some prediction</span></div>
<div class="line">        <span class="keyword">auto</span> loss = lossFunction(pred, ys[sample]);         <span class="comment">// And calculate its error</span></div>
<div class="line"> </div>
<div class="line">        epochLoss = epochLoss + loss;                       <span class="comment">// Store the loss for feedback</span></div>
<div class="line">    }</div>
<div class="line">    optimizer.step();                                       <span class="comment">// Update the parameters</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">auto</span> averageLoss = epochLoss / Val32::create(xs.size());</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Epoch: &quot;</span> &lt;&lt; epoch + 1 &lt;&lt; <span class="stringliteral">&quot; Loss: &quot;</span> &lt;&lt; averageLoss-&gt;getValue() &lt;&lt; std::endl;</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md19"></a>
Verifying the results</h2>
<p>After the training, let's inspect how our network behaves.</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> sample = 0; sample &lt; xs.size(); ++sample) {         <span class="comment">// Go through each example</span></div>
<div class="line">    Vec32 pred = network-&gt;forward(xs[sample]);                  <span class="comment">// Predict result</span></div>
<div class="line">    std::cout &lt;&lt; xs[sample] &lt;&lt; <span class="stringliteral">&quot; -&gt; &quot;</span> &lt;&lt; pred &lt;&lt; <span class="stringliteral">&quot;\t| True: &quot;</span> &lt;&lt; ys[sample] &lt;&lt; std::endl;</div>
<div class="line">}</div>
</div><!-- fragment --><p>In case you got lost along the way, check out the <code>examples/xor_regression.cpp</code> file. It contains the exact same code and is ready to run :)</p>
<h2><a class="anchor" id="autotoc_md20"></a>
Results</h2>
<p>Nice! After compiling and running this code (make sure to use C++17), you should see something like this:</p>
<div class="fragment"><div class="line">Epoch: 1 Loss: 0.263062</div>
<div class="line">Epoch: 2 Loss: 0.211502</div>
<div class="line">(...)</div>
<div class="line">Epoch: 99 Loss: 0.000222057</div>
<div class="line">Epoch: 100 Loss: 0.00020191</div>
<div class="line">Vector(size=2, data={Value(data=0) Value(data=0) }) -&gt; Value(data=0.0191568)    | True: Value(data=0)</div>
<div class="line">Vector(size=2, data={Value(data=1) Value(data=0) }) -&gt; Value(data=0.99998)      | True: Value(data=1)</div>
<div class="line">Vector(size=2, data={Value(data=0) Value(data=1) }) -&gt; Value(data=0.999984)     | True: Value(data=1)</div>
<div class="line">Vector(size=2, data={Value(data=1) Value(data=1) }) -&gt; Value(data=0.0191568)    | True: Value(data=0)</div>
</div><!-- fragment --><p>WOW! The network actually learned the XOR function.</p>
<p>This is it. You should have enough knowledge to start experimenting with <em>Shkyera Engine</em>. Let us know on GitHub what do you think about this project :) </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
